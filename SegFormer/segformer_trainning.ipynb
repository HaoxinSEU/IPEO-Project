{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "class SemanticSegmentationDataset(Dataset):\n",
    "    \"\"\"Image (semantic) segmentation dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, mode=\"train\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Root directory of the dataset containing the images + annotations.\n",
    "            feature_extractor (SegFormerFeatureExtractor): feature extractor to prepare images + segmentation maps.\n",
    "            mode: Whether to load \"training\" or \"validation\" images + annotations.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        #self.feature_extractor = feature_extractor\n",
    "        self.mode = mode\n",
    "        self.transforms = self.create_transforms()\n",
    "        \n",
    "        #sub_path = \"training\" if self.train else \"validation\"\n",
    "        self.img_dir = os.path.join(self.root_dir, \"input\", self.mode)\n",
    "        self.images = sorted([f for _, _, files in os.walk(self.img_dir) for f in files])\n",
    "        self.ann_dir = os.path.join(self.root_dir, \"target\", self.mode)\n",
    "        self.annotations = sorted([f for _, _, files in os.walk(self.ann_dir) for f in files])\n",
    "        \n",
    "    def create_transforms(self):\n",
    "        _transforms = A.Compose([\n",
    "            A.PadIfNeeded(min_height=256, min_width=256, border_mode=0, value=0, mask_value=255),\n",
    "            A.Resize(height=256, width=256), \n",
    "            ToTensorV2(),\n",
    "#             A.Normalize([0.485, 0.456, 0.406, 0], [0.229, 0.224, 0.225, 1])\n",
    "        ], p = 1,\n",
    "        )\n",
    "        return _transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(os.path.join(self.img_dir, self.images[idx])).convert('RGB'))\n",
    "        mask  = np.array(Image.open(os.path.join(self.ann_dir, self.annotations[idx])).convert('L'))\n",
    "        mask[mask > 1] = 255 #change all non-valid label value to 255\n",
    "\n",
    "        # transform\n",
    "        encoded_inputs =  self.transforms(image = image, mask = mask)\n",
    "        return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = './HistForestMapping/'\n",
    "\n",
    "train_dataset = SemanticSegmentationDataset(root_dir=data_dir,mode=\"train\")\n",
    "valid_dataset = SemanticSegmentationDataset(root_dir=data_dir,mode=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the train data on a random sample\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "\n",
    "print('Length of training dataset:',len(train_dataset))\n",
    "print('Length of validation dataset:',len(valid_dataset))\n",
    "\n",
    "random_index = random.randint(0, len(train_dataset) - 1)\n",
    "\n",
    "sample = train_dataset[random_index]  # Get the first sample\n",
    "print(f\"Image shape: {sample['image'].shape}\")\n",
    "print(f\"Mask shape: {sample['mask'].shape}\")\n",
    "\n",
    "def show_sample(image, mask):\n",
    "    colors = [(0, 0, 0), (0, 0.5, 0), (0.5, 0.5, 0.5)]\n",
    "    n_bins = [3]  # Discretizes the interpolation into bins\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list('custom_cmap', colors, N=3)\n",
    "    # Adjust mask for 'NoData' to be white or transparent\n",
    "    mask_display = np.copy(mask)\n",
    "    mask_display[mask == 255] = 2  # 2 corresponds to grey in the custom colormap\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Image\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask_display, cmap=cmap, interpolation='nearest', vmin=0, vmax=2)\n",
    "    plt.title(\"Mask (Forest in Dark Green)\")\n",
    "    plt.show()\n",
    "\n",
    "# Convert tensor to numpy for visualization\n",
    "sample = train_dataset[random_index]\n",
    "image = sample['image'].numpy().transpose(1, 2, 0)  # Assuming image is in CxHxW format\n",
    "mask = sample['mask'].numpy()  # Assuming mask is in HxW format\n",
    "show_sample(image, mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained segformer model from HuggingFace\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "id2label = {0: 'Non-Forest', \n",
    "            1: 'Forest',\n",
    "            255: 'NoData'}\n",
    "label2id = {'Non-Forest' : 0, \n",
    "            'Forest': 1,\n",
    "            'NoData':255}\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b0\",\n",
    "                                                         num_labels=3, \n",
    "                                                         id2label=id2label, \n",
    "                                                         label2id=label2id,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"mean_iou\")\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00006)\n",
    "# move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs): \n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # get the inputs;\n",
    "        pixel_values = batch[\"image\"].to(device).float()\n",
    "        labels = batch[\"mask\"].to(device).long()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss, logits = outputs.loss, outputs.logits\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # evaluate\n",
    "        with torch.no_grad():\n",
    "            upsampled_logits = nn.functional.interpolate(logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            predicted = upsampled_logits.argmax(dim=1)\n",
    "            # note that the metric expects predictions + labels as numpy arrays\n",
    "            metric.add_batch(predictions=predicted.detach().cpu().numpy(), references=labels.detach().cpu().numpy())\n",
    "\n",
    "        # let's print loss and metrics every 100 batches\n",
    "        if idx % 100 == 0:\n",
    "            metrics = metric._compute(references = labels.cpu(), \n",
    "                                      predictions = predicted.cpu(),\n",
    "                                      num_labels=len(id2label), \n",
    "                                      ignore_index=255,\n",
    "                                      reduce_labels=False, # we've already reduced the labels before)\n",
    "          )\n",
    "\n",
    "            print(\"Loss:\", loss.item())\n",
    "            print(\"Mean_iou:\", metrics[\"mean_iou\"])\n",
    "            print(\"Mean accuracy:\", metrics[\"mean_accuracy\"])\n",
    "\n",
    "# Save the model\n",
    "import os\n",
    "os.makedirs('./segformer_model', exist_ok = True)\n",
    "model.save_pretrained(save_directory = './segformer_model/')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
